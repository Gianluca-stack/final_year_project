Text,Subject
the expression out of sight out of mind could easily apply to mistletoe since it thrives in the tops of the dense tree canopies of its host therefore its rarely seen for much of the year but in the fall after the trees lose their leaves this shrubby evergreen can be easily observed growing on the upper tree branches mistletoe is rarely noticed except during the time when deciduous trees have dropped their leaves here in the states our ritual stems from european mistletoe viscum album which resembles american mistletoe in norse mythology a norse goddess declared mistletoe sacred to symbolize love this led to the tradition of kissing under the mistletoe in the 18th century mistletoe was hung during holiday festivals and men would steal kisses from women under it one berry was removed for every kiss received when the berries were gone so were the kisses yet beyond this timeless tradition i suspect most of us take for granted the backstory to this fascinating and very real plant it is also prominent in druid and nordic mythology celtic druids considered the plant sacred and used it as a fertility symbol in ceremonies they hung the plant over windows and doorways to ward off evil native americans used the plant in various ways including as a remedy for toothaches rheumatism and to treat wounds the common holiday mistletoe known as american or oak mistletoe phoradendron leucarpum is harvested in the wild mostly from oklahoma and texas to sell during the holiday season but in america its native to about 26 states its range extends from southern new york south to florida west to new mexico and northeast to kansas missouri illinois and ohio commonly found in oaks mistletoe also grows on a variety of deciduous hardwood trees including maple sycamore hickory beech ash elm and pecan as an evergreen semiparasite it roots beneath the bark of the host tree on branches and trunks and creates its own food through photosynthesis but it obtains water and nutrients through modified roots that penetrate the bark of its host although the genus phoradendron literally means thief of the tree referring to the belief that mistletoe is robbing something from its host mistletoe causes little harm to its host tree the word mistletoe comes from the anglosaxon words for dung mistel and the word for twig tan which appropriately describes mistletoes origin of sprouting where a bird leaves its droppings the berries are a favorite of the mistel thrush the sticky white fruit is poisonous to humans but desired by birds such as robins thrushes bluebirds and cedar waxwings birds spread the seeds by eating the fruit and eliminating them through their droppings and by wiping the sticky pulp off their beaks onto branches where new plants begin growth so there you have it more than you wanted to know about mistletoe but now that you do feel free to use this timely and helpful information next time your holiday party conversation hits that awkward moment of silence weve all been there you can thank me later joe lampl is the host and executive producer of the award winning pbs television series growing a greener world off camera joe dedicates his time to promoting sustainability through his popular books blog podcast series and nationally syndicated newspaper columns follow joe on twitter,Gardening
i think its fairly safe to assume most people dread the mess and work involved in cleaning up all those fall leaves that blanket their yards each year call me weird but dealing with fall leaves in my yard is one of the highlights of the year for me while i dont relish the investment of time in relocating them from the lawn to the beds i do see it for exactly thatan investment for many years ive been gathering blowing and raking leaves onto a flat area of my lawn where i can grind them up with my mulching mower and then rake them back into my beds as a shredded layer of organic mulch even if you dont have enough leaves to collect from your own yard you dont have to look very far to find neighbors or friends who are happy to let you take them off their hands its money in the bank with longterm benefits the shredded leaves will immediately go to work keeping soil and roots warmer retaining moisture and preventing many weeds from germinating over time those leaves will break down into rich organic compost that will do wonders for improving the quality of any soil while its not an overnight transformation in a few years even hard packed clay will improve to an impressive mix of rich loamy soil several inches deep moreover plants and trees love the constant addition of organic matter and nutrients youll love how easy it becomes to dig into that soil when installing new plants thanks to the work of those decaying leaves becoming a permanent part of what lies beneath your feet the steps involved in converting leaves into rich loamy organic matter that adds life to any garden soil is a simple process thats all there is to it in my garden beds im happy to say my former hard red georgia clay is a rich loamy easy to work with soil after about 4  5 years of repeated annual deposits while that may not seem very fast keep in mind its effortless once the leaves are in place and once they do break down as ive written previously it only gets better after that joe lampl is the host and executive producer of the award winning pbs television series growing a greener world off camera joe dedicates his time to promoting sustainability through his popular books blog podcast series and nationally syndicated newspaper columns follow joe on twitter,Gardening
the effort you put in on the front end will come back to you in spades starting a garden from scratch or improving and existing one can seem a bit intimidating but ive done both many times and have learned quite a few valuable lessons along the way i had a chance to put into practice again all that ive learned firsthand after two years in a beautiful thriving garden used for our working set of fresh from the garden we had to change locations for the final season this meant starting from scratch again not a job i was looking forward to but one i knew how to do the tips below will provide you with some of the same information i used to turn barren land into a thriving abundant garden in just a few months scouting the site a universal principal for a garden to look its best is to make sure that you provide the plants with the conditions where they have the best chance to grow i call this right plant right place if you want to create the best opportunity for plants to thrive in your garden plant what grows best with the conditions youve got trying to force a plant that loves sun to grown in the shade or vise versa will only result in a stressed plant and future problems create a deep bed once you locate an appropriate site consider planting in raised beds to me its the best way to provide the ideal environment for plants to thrive it can be as simple as mounding up soil in a deep wide row and angling the sides enough so they dont wash away when watered this choice is certainly the cheapest but you may need to reshape and mound the beds several times each year if you choose to contain the soil within the bed with physical boundaries then youll need to decide on the material for that there are a number of options including wood stone broken concrete retaining blocks and composite plastic boards i used large boards 12 feet long and 12 inches wide the height is more important than the length a deep bed gives ample opportunity for roots to spread out an important key to garden success add great soil once the bed is created the next and most important step in the process is filling it with the best soil i used a blend of organic matter for my garden knowing that great drainage and good soil structure is critical for success using organic material such as compost rotted leaves aged manure etc is an easy way to achieve those results incorporating as little as 25 organic sources will greatly improve existing conditions i filled the garden beds with a mixture of high quality soil products specifically the ingredients to my soil success included these components complete landscape mix clm by mr natural 70 this mix includes composted hen manure expanded slate for drainage worm castings compost and green sand for drainage and potassium worm castings 15 i added additional worm castings worm poop because they add nutrients and help suppress soil diseases composted cow manure black kow brand 5 theres no secret to the benefits of incorporating manure into garden soil i added this component to increase the organic matter and to improve the soil structure that black kow offers it is pure without fillers and always consistent a bagged high quality cow manure is an easy way to improve soil compost 10 homemade compost is the best ingredient you can add to any soil a little goes a long way to improve soil structure moisture retention drainage and nutrition add the right plants and be proactive youve heard the old saying an ounce of preventionwell in the garden it can be worth a pound of fresh vegetables or flowers i call it the difference between being proactive and reactive being proactive allows you to catch potential problems early and deal with them in time to prevent them from becoming a bigger problem that requires more drastic measures first put the right plants in the right place patrol your garden as often as possible to scout for potential pests and disease problems i did every morning and found it very relaxing it gave me a chance to stay connected to what was going on in the garden but be sure while on patrol to look closely at your plants many looming problems lie under leaves and near the soil where it is easy miss water properly another way i made sure my plants stayed healthy and well watered was to irrigate with soaker hoses watering overhead can potentially lead to disease if the leaf surface stays wet for too long soaker hoses on the other hand allow water to seep out slowly right at the soil surface this keeps the leaves dry and gives the roots time to take in all the moisture they need creating a great looking garden at home does require a bit of planning and work on the front end but long lasting fantastic results will be the reward for years to come joe lampl is the host and executive producer of the award winning pbs television series growing a greener world off camera joe dedicates his time to promoting sustainability through his popular books blog podcast series and nationally syndicated newspaper columns follow joe on twitter,Gardening
removing debris from the garden reduces overwintering pests and diseases some gardeners will do whatever it takes to keep their gardens growing as long as possible with the right combination of techniques one could potentially garden year round even in the coldest climates then there is the other group those gardeners ready to retire their garden for the season by the time autumn rolls around if you see yourself in this second group a few steps should be taken first to ensure a carefree start to your next gardening season one of the first tasks in putting the fall garden to bed includes removing all weeds now before you stop reading this article in protest know that the weeds are on the verge of releasing potentially millions of seeds any effort you can make now to prevent this will make future work that much easier its often said one weed removed today is thousands less to remove tomorrow most weeds in the garden are annuals which reproduce from seeds remove any weeds with seed heads or flowers promptly i dont even put them in my compost pile for fear of the seeds surviving the composting process this occurs when temperatures dont get hot enough to kill the seeds next make sure the garden is free of all debris besides the obvious consideration of a neater better looking garden dead branches leaves and such can be a significant hiding place and home for many types of pests and diseases that overwinter in the protection of these materials this is not an indictment of leaf mulch in your garden in fact it is just the opposite i am a strong advocate for the use of natural recycled organic material as mulch and i see it as a critical component to a healthy garden however i do strongly suggest that the mulch and leaves be kept 23 inches away from the base of all shrubs and trees otherwise it can trap moisture at the trunk or base and provide an easy way for pests and diseases to potentially enter the plant the next task is to prune away and remove any diseased dead or dying wood removing these potential habitats now reduces the possibility of an infestation later selective pruning at this time is also important for another reason branches that are growing inward as opposed to outward as they should are more likely to cross and rub against other branches crossing branches can be abrasive and the constant rubbing can open the bark layer exposing yet another way problems can enter the plant once the clean up is complete its time to put away the hoses drain the irrigation lines and bring in all the tools and equipment just be sure you really are finished for the season before you complete these tasks i cant tell you how many times ive needed access to water at the far end of my garden after the hoses are stored and irrigation lines have been cleared however given this advice id rather retrieve a hose than have to dig out and repair a cracked irrigation line due to freezing the few extra steps now allow me to get off to a fast start next spring in a cleaner healthier garden joe lampl is the host and executive producer of the award winning pbs television series growing a greener world off camera joe dedicates his time to promoting sustainability through his popular books blog podcast series and nationally syndicated newspaper columns follow joe on twitter,Gardening
have we become too busy in our daily lives to actually enjoy the process of gardening ive had a fascination with consumer trends in gardening for several years i think its because im so involved in what people are doing in and around their gardens it helps to know how they believe theyll spend their time and money in the future i dont like what i see although gardening is still americas number one pastime nurseries have reported a decline in sales in the past few years the media along with consumer trade groups and others have taken note i serve on a committee for the garden writers association that studies these trends and develops questions to anticipate future behavior millions of dollars are spent each year researching the reasons why gardening sales are flat or declining and why gardening shows and books arent as popular as before to me one answer stands out were far too busy people are not as interested in gardening because they feel they dont have the time anymore to garden former avid gardeners are throwing in the trowel on existing gardens and potential gardeners are shying away from any outdoor activity that is associated with the word maintenance i believe being too busy is exactly the reason we need to garden these days we want everything now so we can get on to the next task even microwave popcorn that only took three minutes has a new and improved version to pop more quickly this quick fix resultsoriented mentality that has taken over our lives has now found its way into gardening plants are being developed that are considered goof proof so we dont have to take the time to water or care for them theres even a seed company that now offers a line of prehardened off seedlings so we dont have to bother with acclimating them to your environment before planting as a passionate gardener who never seems to have any spare time i should be thrilled with this news and yet i find it sad to me one of the greatest pleasures of gardening is in the process its the act of gardening not so much as the results i understand and in some ways appreciate the efforts to make gardening easier and more convenient it at least allows some to garden who would otherwise choose another activity but i hope we all slow done enough to appreciate the subtleties of gardening thats where the real beauty is in fact the slowness of gardening is what allows me to catch my breath and to escape the otherwise crazy pace on any given day i need gardening to remain slow and not so convenient i dont mind the labor it sometimes requires at least it reminds me to get out and pay a visit i dont look at gardening as a chore i look at it as an opportunity lets find ways to save time in other areas of our lives so we can spend more time in the garden enjoying the process joe lampl is the host and executive producer of the award winning pbs television series growing a greener world off camera joe dedicates his time to promoting sustainability through his popular books blog podcast series and nationally syndicated newspaper columns follow joe on twitter,Gardening
a sin resonator under localized heating different modes have different effective temperatures depending on the spatial overlap between the local temperature and the dissipation density of the mode creditsteven burrowsregal group researchers discovered nonuniform temperature distributions in micromechanical resonators impacting their design and performance in quantum science and precision sensing when measuring minor changes for quantities like forces magnetic fields masses of small particles or even gravitational waves physicists use micromechanical resonators which act like tuning forks resonating at specific frequencies traditionally it was assumed that the temperature across these devices is uniform however new research from jila fellow and university of colorado boulder physics professor cindy regal and her team dr ravid shaniv and graduate student chris reetz has found that in specific scenarios such as advanced studies looking at the interactions between light and mechanical objects the temperature might differ in various resonator parts which leads to unexpected behaviors their observations published in physical review research can potentially revolutionize the design of micromechanical resonators for quantum technology and precision sensing in quantum science experiments understanding this temperature differences ramifications will allow you to generate your mechanical quantum state with better fidelity and keep it unperturbed for longer both essential starting points for quantum applications elaborated jila postdoctoral research associate and first author ravid shaniv due to their flexible design micromechanical resonators are a standard tool in many different fields of physics these devices are often made of silicon or similar materials and can take various shapes beams cantilevers membranes or disks their small size allows them to oscillate at high frequencies often in the megahertz mhz range to gigahertz ghz the versatility of a micromechanical resonators design also allows physicists to finetune their oscillations just as a guitar string can vibrate in multiple ways with the whole string moving back and forth or just parts wiggling while the rest remains still micromechanical resonators can oscillate in different patterns or modes the most familiar mode is the fundamental mode where the entire structure moves in unison but there are also higherorder modes where other resonator parts move in more complex patterns to measure a resonators motion physicists use laser beams the resonator acts like a moving mirror and the laser light that bounces off carries information about its position when compared to light that bounces off a separate fixed mirror an interference pattern is developed revealing the resonators motion to ultrahigh precision over the years of observing these modes optically and discussing them with other physicists shaniv and regal realized something interesting people have observed that some of these modes exhibit more thermal motion than others shaniv stated typically people want to eliminate this motion as much as possible because it could overshadow any small effect they want to sense physicists have posited that this excess of thermal motion could be due to the resonator absorbing laser light in the form of heat different resonator modes can have different movement patterns leading to varying areas of stress or strain which can in turn lead to distinct magnitudes of thermal motion in many observations the more complex the mode of the resonator the more its thermal energy deviates from previous theories which suggested the temperature for every mode was identical shaniv continued we wanted to track down the reason for that and how you can achieve the optimum design for these modes to dive deeper into this temperature conundrum shaniv and regal created specific temperature profiles for each mode to do this the researchers utilized a phononic crystal comprised of silicon nitride the crystal acted as a playground where the researchers could engineer the resonator modes and generate varying temperature profiles allowing them to observe the induced thermal motion of each resonator mode to create the temperature profile the team heated a point on the crystal to very high temperatures while keeping the resonator edge at room temperature after a profile was developed and thermal motion was measured the researchers found some rather interesting results depending on the mode geometry some modes showed increased thermal motion while even though parts of the resonator were extremely hot others showed only mild heating and some exhibited no heating at all by turning the knob all the way in the experiment you could see this striking difference elaborated regal shaniv continued looking at these really large temperature differences between modes we were able to construct the temperature profile of a resonator directly from measured thermal motion and even find some material parameters that are typically not straightforward to evaluate for example the emissivity which is how much radiation our device emits by seeing which modes correlated to different thermal motions the team could begin to predict how the resonators performance may change depending on their mode as regal explained a natural next step is to ask whether these concepts can be put to use not only in understanding how to keep resonators cold for quantum studies but also in thermal sensing with the insights gained the scientific and engineering communities could make significant strides in designing and applying these minuscule yet crucial devices we actually gave in our paper a real figure of merit with which groups can work in this direction shaniv elaborated for example we now have a specific parameter to throw as a constraint into the computer and try to generate the best possible resonator reference direct measurement of a spatially varying thermal bath using brownian motion by ravid shaniv chris reetz and cindy a regal 6 november 2023 physical review research doi 101103physrevresearch5043121,Physics
researchers at forschungszentrum jlich have developed an ai capable of formulating physical theories by recognizing patterns in complex data sets a feat historically achieved by great physicists like isaac newton and albert einstein this ai part of the physics of ai initiative simplifies complex interactions in data to develop new theories differing from conventional approaches by making the theories explainable and grounded in the language of physics credit scitechdailycom the development of a new theory is typically associated with the greats of physics you might think of isaac newton or albert einstein for example many nobel prizes have already been awarded for new theories researchers at forschungszentrum jlich have now programmed an artificial intelligence that has also mastered this feat their ai is able to recognize patterns in complex data sets and to formulate them in a physical theory the development of a new theory is typically associated with the greats of physics you might think of isaac newton or albert einstein for example many nobel prizes have already been awarded for new theories researchers at forschungszentrum jlich have now programmed an artificial intelligence that has also mastered this feat their ai is able to recognize patterns in complex data sets and to formulate them in a physical theory in the following interview prof moritz helias from forschungszentrum jlichs institute for advanced simulation ias6 explains what the physics of ai is all about and to what extent it differs from conventional approaches you usually start with observations of the system before attempting to propose how the different system components interact with each other in order to explain the observed behavior new predictions are then derived from this and put to the test a wellknown example is isaac newtons law of gravitation it not only describes the gravitational force on earth but it can also be used to predict the movements of planets moons and comets  as well as the orbits of modern satellites  fairly accurately however the way in which such hypotheses are reached always differs you can start with general principles and basic equations of physics and derive the hypothesis from them or you can choose a phenomenological approach limiting yourself to describing observations as accurately as possible without explaining their causes the difficulty lies in selecting a good approach from the numerous approaches possible adapting it if necessary and simplifying it in general it involves an approach known as physics for machine learning in our working group we use methods of physics to analyze and understand the complex function of an ai the crucial new idea developed by claudia merger from our research group was to first use a neural network that learns to accurately map the observed complex behavior to a simpler system in other words the ai aims to simplify all the complex interactions we observe between system components we then use the simplified system and create an inverse mapping with the trained ai returning from the simplified system to the complex one we then develop the new theory on the way back the complex interactions are built up piece by piece from the simplified ones ultimately the approach is therefore not so different from that of a physicist with the difference being that the way in which the interactions are assembled is now read from the parameters of the ai this perspective on the world  explaining it from interactions between its various parts that follow certain laws  is the basis of physics hence the term physics of ai we used a data set of black and white images with handwritten numbers for example which is often used in research when working with neural networks as part of her doctoral thesis claudia merger investigated how small substructures in the images such as the edges of the numbers are made up of interactions between pixels groups of pixels are found that tend to be brighter together and thus contribute to the shape of the edge of the number the use of ai is a trick that makes the calculations possible in the first place you very quickly reach a very large number of possible interactions without using this trick you could only look at very small systems nevertheless the computational effort involved is still high which is due to the fact that there are many possible interactions even in systems with many components however we can efficiently parameterize these interactions so that we can now view systems with around 1000 interacting components ie image areas with up to 1000 pixels in the future much larger systems should also be possible through further optimization many ais aim to learn a theory of the data used to train the ai however the theories that the ais learn usually cannot be interpreted instead they are implicitly hidden in the parameters of the trained ai in contrast our approach extracts the learned theory and formulates it in the language of interactions between system components which underlies physics it thus belongs to the field of explainable ai specifically the physics of ai as we use the language of physics to explain what the ai has learned we can use the language of interactions to build a bridge between the complex inner workings of ai and theories that humans can understand reference learning interacting theories from data by claudia merger alexandre ren kirsten fischer peter bouss sandra nestler david dahmen carsten honerkamp and moritz helias 20 november 2023 physical review x doi 101103physrevx13041033,Physics
hybrid integration of a designer nanodiamond with photonic circuits via ring resonators creditsteven burrowssun group jila breakthrough in integrating artificial atoms with photonic circuits advances quantum computing efficiency and scalability in quantum information science many particles can act as bits from individual atoms to photons at jila researchers utilize these bits as qubits storing and processing quantum 1s or 0s through a unique system while many jila fellows focus on qubits found in nature such as atoms and ions jila associate fellow and university of colorado boulder assistant professor of physics shuo sun is taking a different approach by using artificial atoms or semiconducting nanocrystals with unique electronic properties by exploiting the atomic dynamics inside fabricated diamond crystals physicists like sun can produce a new type of qubit known as a solidstate qubit or an artificial atom because these artificial atoms do not move one way to let them talk to each other is to place them inside a photonic circuit the photons traveling inside the photonic circuit can connect different artificial atoms like hot air moving through an air duct to warm a cold room photons move through the quantum circuit to induce interactions between the artificial atoms having an interface between artificial atoms and photons allows you to achieve precise control of the interactions between two artificial atoms explained sun historically there have been problems with integrating artificial atoms with photonic circuits this is because creating the artificial atoms where atoms are knocked out of a diamond crystal is a very random process leading to random placement of the artificial atoms random number of artificial atoms at each location and random color each artificial atom emits adding to the issue is the incompatibility between the material that hosts the artificial atoms and the material that hosts the photonic circuit despite years of research scientists have yet to find a suitable material that can be a good host of both making the integration more difficult in a new nano letters paper sun his research team and collaborators from stanford university proposed a new method that would pave the way to solving these two challenges enabling a more complicated integrated quantum photonic circuit this new technique suggests bigger implications for the future of quantum information science including a way to scale up the circuits we now have a way to integrate multiple artificial atoms on one photonic chip explained first author and jila graduate student kin fung ngan historically diamond has been a popular choice for hosting artificial atoms as its incredibly pure with a large bandgap allowing physicists more control over the excitation of the atom inside the crystal our qubits are embedded into the diamond explained ngan the benefit here is that we dont need any additional apparatus to hold them in space however the downside of using a diamond as a qubit host is that its incredibly hard to carve making it difficult to define photonic circuits on them it is also difficult to get a large diamond piece unlike other photonic materials such as silicon nitride where eightinch wafers are readily available to make a large quantum photonic circuit the diamondbased artificial atoms must be placed inside a photonic circuit based on a different material such as silicon nitride sun ngan and jila graduate student yuan zhan had to find ways to integrate the two different components residing in different materials if the integration was not achieved properly you may have a weaker coupling between the atom and the photon or a loss of photons during transmission these effects will generate errors when we use photons to mediate interactions between two artificial atoms elaborated sun while previous studies tried to combine the two materials using external junctions the researchers took a different approach by embedding a nanosized chunk of diamond containing the artificial atom directly inside the silicon nitride circuit using an ultraprecise placement method for arranging the nanodiamonds on the chip the researchers added nanodiamonds containing an artificial atom to the chip coated the entire chip with a silicon nitride layer and then fabricated photonic circuits centered around each atom this process ensures the maximum coupling between the artificial atom and the photonic circuit after embedding the artificial atoms into the silicon nitride circuit the researchers tested the coupling efficiency by exciting the artificial atoms and measuring the light collected by the photonic circuit their tests showed that the light shone brighter when the atom was placed inside an optical cavity revealing the ability to efficiently couple light from the artificial atom to the photonic circuit besides contributing to better compatibility the ultraprecise placement technique allowed researchers to align several artificial atoms in a row on the same circuit showing the flexibility of their process and its capability to host multiple qubits at once currently ngan zhan and other jila researchers are working on techniques to make these artificial atoms interact with each other with the help of photons and to entangle two artificial atoms with the help of photons while this current quantum photonic circuit leverages photons as mediators for interactions between the artificial atoms or qubits the photons themselves can also act as separate qubits within the system the circuit can indeed work for two purposes sun elaborated by embedding artificial atoms inside a photonic quantum circuit we can use the artificial atoms as sources and memories of single photons potentially reducing the resource required to build a photonic quantum processor the combination of the material compatibility and the duality of the qubits in the system suggests that suns circuit design could have big implications for the future of quantum information offering an effective way to scale up the integrated quantum photonic systems reference quantum photonic circuits integrated with color centers in designer nanodiamonds by kinfung ngan yuan zhan constantin dory jelena vukovi and shuo sun 2 october 2023 nano letters doi 101021acsnanolett3c02645,Physics
researchers observed the dynamic phases of bcs superconductor interactions in a cavity qed by measuring the light leakage from the cavity credit steven burrowsrey and thompson groups superconductivity makes physics seem like magic at cold temperatures superconducting materials allow electricity to flow indefinitely while expelling outside magnetic fields causing them to levitate above magnets mris maglev trains and highenergy particle accelerators use superconductivity which also plays a crucial role in quantum computing quantum sensors and quantum measurement science someday superconducting electric grids might deliver power with unprecedented efficiency yet scientists lack full control over conventional superconductors these solid materials often comprise multiple kinds of atoms in complicated structures that are difficult to manipulate in the lab its even harder to study what happens when theres a sudden change such as a spike in temperature or pressure that throws the superconductor out of equilibrium quantum theory has predicted intriguing behaviors when a superconductor is driven out of equilibrium however it has been challenging to perturb these materials in the lab without disrupting their delicate superconducting properties leaving these predictions untested however scientists can obtain surprisingly deep insights into superconductivity by studying it with fully controllable arrays of atoms in a gas that is the approach of a research collaboration at jila a joint institute of the national institute of standards and technology nist and the university of colorado boulder in their latest work jila researchers caused a gas of strontium atoms to act like a superconductor even though the strontium atoms themselves are not superconducting they follow the same rules of quantum physics the researchers could make atoms in a gas interact in a way that preserves the sorts of interactions responsible for superconductivity while suppressing other competing complex interactions by throwing the atoms out of equilibrium the researchers saw changes in atomic interactions that would affect the properties of actual superconductors with their strontium gas acting as a quantum simulator the researchers were able to observe a behavior of superconductors that has been predicted to exist for years this study published in nature offers new insight into how superconductors work when appropriately driven out of equilibrium and sheds light on how to make superconductors more robust and how to use their unique properties in other quantum technologies in a normal material electrons move in an incoherent way bumping into one another constantly normally electrons repel each other as they move they collide losing energy and generating heat thats why electric currents dissipate when electrons flow in a metallic wire in a superconductor however electrons join up into weakly bonded pairs called cooper pairs when these pairs form they all tend to move coherently and that is why they flow through the material with no resistance the physics is simple in some sense explains theoretical physicist ana maria rey a nist and jila fellow cooper pairs exist in a lowenergy state because vibrations in the materials crystalline structure pull the electrons together when formed cooper pairs prefer to act coherently and lock together the cooper pairs are kind of like arrows that want to line up in the same direction to unlock them or make one of the arrows point along a different direction you need to add extra energy to break the cooper pairs rey explains the energy that you need to add to unlock them is called an energy gap stronger interactions between the atoms create a larger energy gap because the attraction that keeps the cooper pairs locked is so strong overcoming that energy gap takes a lot of energy away from the cooper pairs so this energy gap acts as a buffer letting the cooper pairs remain happily locked in phase this all works when the system is in equilibrium but when you introduce a sudden rapid change the superconductor falls out of equilibrium or becomes quenched for decades scientists have wanted to know what happens to superconductivity following a quench that is abrupt but not so strong to completely break the cooper pairs said jila physicist james thompson in other words how robust are these things thompson said theorists predicted three different possibilities or phases that could happen when the superconductor is quenched think of it like a big group of square dancers thompson says at first everyone is in sync keeping to the beat of the music then some people get a little tired or some others start moving a little too fast they crash into each other and it turns into a mosh pit thats phase i when superconductivity collapses in phase ii the dancers get off the beat but manage to stay in sync superconductivity survives the quench scientists have been able to observe and study these two phases but they have never seen a longpredicted third phase in which the superconductivity of the system oscillates over time in this phase our dancers will move a bit faster or a bit slower at times but no one crashes that means sometimes its a weaker superconductor and sometimes its a stronger superconductor until now no one had been able to observe that third phase working with reys theory group thompsons team at jila lasercooled and loaded strontium atoms into an optical cavity a space with highly reflective mirrors at either end laser light bounces back and forth millions of times before some light leaks out at one end the light in the cavity mediated interactions between the atoms causing them to align into a superposition state  meaning they are in both the excited and ground state at the same time  and to lock in phase like cooper pairs do rey explains using lasers scientists can quench the system and by measuring the light that leaks out they learn how the energy gap has changed over time with this quantum superconductor simulation they were able to observe all three dynamic phases for the first time they found that in the third phase the energy gap can keep superconductivity going even when the system is out of equilibrium using quantum simulators like this could help scientists engineer unconventional or more robust superconductors and better understand the physics of superconductors in general its also a counterintuitive way for scientists who work in measurement science to see atomic interactions like the ones that cause the energy gap as a benefit not a curse in measurement science interactions are usually bad but here when interactions are strong they can help you the gap protects the system  everything flows rey says at the heart of this idea you could have something that oscillates forever having something that oscillates forever is a dream for quantum technology thompson adds because it would let sensors work better for longer much like the superconductors groups of atoms photons and electrons in quantum sensors need stay in sync or coherent to work and we dont want them to turn into a quantum mosh pit or dephase i am stoked that one of the dynamical phases that we observe can be used to protect quantum optical coherence against dephasing for instance this may one day allow an optical atomic clock to tick for longer thompson said it represents a whole new way to increase the precision and sensitivity of quantum sensors a topic that is at the frontier of quantum metrology or measurement science we want to harness the many atoms and take advantage of the interactions to build a better sensor reference observing dynamical phases of bcs superconductors in a cavity qed simulator by dylan j young anjun chu eric yilun song diego barberena david wellnitz zhijing niu vera m schfer robert j lewisswan ana maria rey and james k thompson 24 january 2024 nature doi 101038s4158602306911x,Physics
lsu researchers have made a significant discovery related to the fundamental properties and behavior of plasmonic waves which can lead ot the development of more sensitive and robust quantum technologies credit lsu quantum researchers uncover important implications for quantum technology in a recent publication in nature physics the lsu quantum photonics group offers fresh insights into the fundamental traits of surface plasmons challenging the existing understanding based on experimental and theoretical investigations conducted in associate professor omar magaaloaizas laboratory these novel findings mark a significant advancement in quantum plasmonics possibly the most noteworthy in the past decade while prior research in the field has predominantly focused on the collective behaviors of plasmonic systems the lsu group adopted a distinct approach by viewing plasmonic waves as a puzzle they were able to isolate multiparticle subsystems or break down the puzzle into pieces this allowed the team to see how different pieces work together and revealed a different picture or in this case new behaviors for surface plasmons plasmons are waves that move along the surface of metals when light is coupled to charge oscillations much like tossing pebbles into water generates ripples plasmons are ripples traveling along metal surfaces these minute waves operate on a nanometer scale rendering them crucial in fields such as nanotechnology and optics what we found is that if we look at the quantum subsystems of plasmonic waves we can see inverse patterns sharper patterns and opposite interference which is completely opposite to the classical behavior explained riley dawkins a graduate student and cofirst author of the study who led the theoretical investigation using light aimed at a gold nanostructure and observing the behavior of scattered light the lsu quantum group observed that surface plasmons can exhibit characteristics of both bosons and fermions which are fundamental particles in quantum physics this means that quantum subsystems can exhibit nonclassical behaviors such as moving in different directions depending on specific conditions imagine you are riding a bike you would believe that most of your atoms are moving in the same direction as the bike and that is true for most of them but in fact there are some atoms moving in the opposite direction explained magaaloaiza one of the consequences of these results is that by understanding these very fundamental properties of plasmonic waves and most importantly this new behavior one can develop more sensitive and robust quantum technologies in 2007 the use of plasmonic waves for anthrax detection sparked research into employing quantum principles for improved sensor technology presently researchers are striving to integrate these principles into plasmonic systems to create sensors with heightened sensitivity and precision this advancement holds significant promise across diverse fields including medical diagnostics drug development simulations environmental monitoring and quantum information science the study is poised to make a significant impact on the field of quantum plasmonics as researchers worldwide will leverage the findings for quantum simulations chenglong you assistant research professor and corresponding author emphasized our findings not only unveil this interesting new behavior in quantum systems but it is also the quantum plasmonic system with the largestever number of particles and that alone elevates quantum physics to another level graduate student and cofirst author mingyuan hong led the experimental phase of the study despite the complexities of quantum plasmonics systems hong noted that his primary challenges during the experiments were external disturbances the vibrations from various sources such as road construction posed a significant challenge due to the extreme sensitivity of the plasmic sample nevertheless we eventually succeeded in extracting quantum properties from plasmonic waves a breakthrough that enhances sensitive quantum technologies this achievement could open up new possibilities for future quantum simulations titled nonclassical nearfield dynamics of surface plasmons the research was conducted entirely at lsu all the authors of this study are affiliated with lsu physics  astronomy we even have a coauthor who was a high school student at the time which im very proud of said magaaloaiza the illustration to the left shows a red laser beam exciting plasmonic waves on the surface of a metallic gold nanostructure these are then scattered by the slit to produce multiparticle systems with specific quantum properties these multiparticle systems are indicated by the spheres our manuscript describes the quantum dynamics behind this process this new research is prefaced by observation of the modification of quantum statistics of plasmonic systems in nature communications references nonclassical nearfield dynamics of surface plasmons by mingyuan hong riley b dawkins benjamin bertoni chenglong you and omar s magaaloaiza 29 february 2024 nature physics doi 101038s4156702402426y observation of the modification of quantum statistics of plasmonic systems by chenglong you mingyuan hong narayan bhusal jinnan chen mario a quirozjurez joshua fabre fatemeh mostafavi junpeng guo israel de leon roberto de j lenmontiel and omar s magaaloaiza 27 august 2021 nature communications doi 101038s41467021254894 the quantum photonics group in the department of physics and astronomy at lsu investigates novel properties of light and their potential for developing quantum technologies the team also conducts experimental research in the fields of quantum plasmonics quantum imaging quantum metrology quantum simulation quantum communication and quantum cryptography,Physics
researchers have devised a method to accurately measure an atoms threedimensional position with a single image revolutionizing quantum mechanics experiments and material development by facilitating precise atom manipulation and tracking for over ten years physicists have been able to pinpoint the exact positions of individual atoms with a precision finer than onethousandth of a millimeter using a specialized microscope however this method has so far only provided the x and y coordinates information on the vertical position of the atom  ie the distance between the atom and the microscope objective  is lacking a new method has now been developed that can determine all three spatial coordinates of an atom with one single image this method  developed by the university of bonn and university of bristol  is based on an ingenious physical principle the study was recently published in the specialist journal physical review a anyone who has used a microscope in a biology class to study a plant cell will probably be able to recall a similar situation it is easy to tell that a certain chloroplast is located above and to the right of the nucleus but are both of them located on the same plane once you adjust the focus on the microscope however you see that the image of the nucleus becomes sharper while the image of the chloroplast blurs one of them must be a little higher and one a little lower than the other however this method cannot give us precise details about their vertical positions this is how it looks in practice the different rotational directions of the various dumbbells indicate that the atoms lie in different planes credit iapuniversity of bonn the principle is very similar if you want to observe individual atoms instead of cells socalled quantum gas microscopy can be used for this purpose it allows you to straightforwardly determine the x and y coordinates of an atom however it is much more difficult to measure its z coordinate ie the distance to the objective lens in order to find out on what plane the atom is located multiple images must be taken in which the focus is shifted across various different planes this is a complex and timeconsuming process we have now developed a method in which this process can be completed in one step explains tangi legrand from the institute of applied physics iap at the university of bonn to achieve this we use an effect that has already been known in theory since the 1990s but which had not yet been used in a quantum gas microscope to experiment on the atoms it is first necessary to cool them down significantly so that they are barely moving afterward it is possible for example to trap them in a standing wave of laser light they then slip into the troughs of the wave similar to how eggs sit in an egg box once trapped to reveal their position they are exposed to an additional laser beam which stimulates them to emit light the resulting fluorescence shows up in the quantum gas microscope as a slightly blurred round speck the image of an atom produced by a quantum gas microscope is normally a round slightly blurred speck the researchers have distorted it into a dumbbell shape the image shows the theoretical prediction the direction in which the dumbbell is pointing shows the z coordinate credit iapuniversity of bonn we have now developed a special method to deform the wavefront of the light being emitted by the atom explains dr andrea alberti the researcher who has now moved from the iap to the max planck institute of quantum optics in garching also participated in the study instead of the typical round specks the deformed wavefront produces a dumbbell shape on the camera that rotates around itself the direction in which this dumbbell points is dependent on the distance that the light had to travel from the atom to the camera the dumbbell thus acts a bit like the needle on a compass allowing us to read off the z coordinate according to its orientation says prof dr dieter meschede the iap researcher whose research group carried out the study is also a member of the transdisciplinary research area matter at the university of bonn the new method makes it possible to precisely determine the position of an atom in three dimensions with one single image this is important for example if you want to carry out quantum mechanics experiments with atoms because it is often essential to be able to precisely control or track their position this allows researchers to make the atoms interact with one another in the desired way furthermore the method could also be used to help develop new quantum materials with special characteristics for example we could investigate which quantum mechanical effects occur when atoms are arranged in a certain order explains dr carrie weidner from the university of bristol this would allow us to simulate the properties of threedimensional materials to some extent without having to synthesize them reference threedimensional imaging of single atoms in an optical lattice via helical pointspreadfunction engineering by tangi legrand falkrichard winkelmann wolfgang alt dieter meschede andrea alberti and carrie a weidner 5 march 2024 physical review a doi 101103physreva109033304 the university of bonn and the university of bristol both participated in the study the research was financed by the german research foundation dfg,Physics
electrons whizzing through the kagome metal fe3sn2 are influenced by the proximity of a flat band shown by the reflection of the top ball on a flat surface this causes the electronic charge to be fractionalized or split shown here by the appearance of the lower ball researchers have now observed this effect spectroscopically credit paul scherrer institute  sandy ekahana quantum mechanics tells us that the fundamental unit of charge is unbreakable  but exceptions exist a research team led by the paul scherrer institute has spectroscopically observed fractionalization of electronic charge in an ironbased metallic ferromagnet experimental observation of the phenomenon is not only of fundamental importance since it appears in an alloy of common metals at accessible temperatures it holds potential for future exploitation in electronic devices the discovery is published in the journal nature basic quantum mechanics tells us that the fundamental unit of charge is unbreakable the electron charge is quantized yet we have come to understand that exceptions exist in some situations electrons arrange themselves collectively as if they were split into independent entities each possessing a fraction of the charge the fact that charge can be fractionalised is not new it has been observed experimentally since the early 1980s with the fractional quantum hall effect in this the conductance of a system in which electrons are confined to a twodimensional plane is observed to be quantized in fractional  rather than integer  units of charge the hall effect provides an indirect measure of charge fractionalization through a macroscopic manifestation of the phenomenon the voltage as such it does not reveal the microscopic behavior  the dynamics  of fractional charges the research team a collaboration between institutions in switzerland and china has now revealed such dynamics via spectroscopy of electrons emitted from a ferromagnet when illuminated by a laser to fractionalise charges you need to take electrons to a strange place where they stop following normal rules in conventional metals electrons typically move through the material generally ignoring each other apart from the occasional bump they possess a range of different energies the energy levels in which they lie are described as dispersive bands where the kinetic energy of the electrons depends on their momenta in some materials certain extreme conditions can push electrons to start interacting and behaving collectively flat bands are regions in the electronic structure of a material where the electrons all lie in the same energy state ie where they have nearly infinite effective masses here electrons are too heavy to escape each other and strong interactions between electrons reign rare and sought after flat bands can lead to phenomena including exotic forms of magnetism or topological phases such as fractional quantum hall states to observe the fractional quantum hall effect strong magnetic fields and very low temperatures are applied which suppress the kinetic energy of electrons and promote strong interactions and collective behavior the research team could achieve this in a different way without application of a strong magnetic field by creating a lattice structure that reduces electron kinetic energies and allows them to interact such a lattice is the japanese woven bamboo kagome mat which characterizes atomic layers in a surprisingly large number of chemical compounds they made their discovery in fe3sn2 a compound consisting only of the common elements iron fe and tin sn assembled according to the kagome pattern of corner sharing triangles laser arpes allows a closer look the researchers did not set out to observe charge fractionalization in kagome fe3sn2 instead they were simply interested in verifying whether flat bands existed as predicted for this ferromagnetic material using laser angle resolved photoemission spectroscopy laser arpes at the university of geneva with a very small beam diameter they could probe the local electronic structure of the material at an unprecedented resolution the band structure in kagome fe3sn2 is different depending on which ferromagnetic domain you are probing we were interested to see whether using the microfocused beam we could detect inhomogeneities in the electronic structure correlated to domains that had been previously missed says sandy ekahana postdoctoral fellow in the quantum technology group at psi and first author of the study electron pockets and colliding bands focusing on certain crystal domains the team identified a feature known as electron pockets these are regions in the momentum space of a materials electronic band structure where the energy of electrons is at a minimum effectively forming pockets where electrons hang out here the electrons behave as collective excitations or quasiparticles on examining these closely the researchers detected strange features in the electronic band structure that were not fully explained by theory the laser arpes measurements revealed a dispersive band which did not match with density functional theory dft calculations  one of the most established methods to study electron interactions and behaviors in materials it quite often happens that dft doesnt quite match but from an experimental point of view alone this band was extremely peculiar it was extremely sharp but then it suddenly cut off this is not normal  usually bands are continuous explains yona soh scientist at psi and corresponding author of the study the researchers realized that they were observing a dispersive band interacting with a flat band predicted to exist by colleagues from epfl the observation of a flat band interacting with a dispersive band is itself of deep interest it is believed that the interaction between flat and dispersive bands allows new phases of matter to emerge such as marginal metals where electrons do not travel much further than their quantum wavelength and peculiar superconductors there has been a lot of theoretical discussion about the interaction between flat and dispersive bands but this is the first time that a new band caused by this interaction has been discovered spectroscopically says soh weird electron behavior gets even weirder fractionalization of charge the consequences of this observation are even more profound where the two bands meet they hybridize to make a new band the original dispersive band is occupied the flat band is unoccupied as it lies above the fermi level  a concept that describes the cutoff between occupied and unoccupied energy levels when the new band is created the charge is split between the original dispersive band and the new band this means that each band contains only a fraction of the charge in this way the measurements by ekahana and colleagues provide direct spectroscopic observation of charge fractionalization achieving and observing states in which charge is fractionalised is exciting not only from the perspective of fundamental research says gabriel aeppli head of the photon science division at psi and professor at epfl and eth zurich who proposed the study we observe this in an alloy of common metals at low but still relatively accessible temperatures this makes it worthwhile considering whether there are electronic devices that might exploit fractionalization reference anomalous electrons in a metallic kagome ferromagnet by sandy adhitia ekahana y soh anna tamai daniel goslbezmartnez mengyu yao andrew hunter wenhui fan yihao wang junbo li armin kleibert c a f vaz junzhang ma hyungjun lee yimin xiong oleg v yazyev felix baumberger ming shi and g aeppli 6 march 2024 nature doi 101038s4158602407085w,Physics
researchers have developed a method to measure gravity at a microscopic level marking a significant advancement in understanding quantum gravity credit scitechdailycom physicists successfully measure gravity in the quantum world detecting weak gravitational pull on a tiny particle with a new technique that uses levitating magnets putting scientists closer to solving mysteries of the universe scientists are a step closer to unraveling the mysterious forces of the universe after working out how to measure gravity on a microscopic level experts have never fully understood how the force discovered by isaac newton works in the tiny quantum world even einstein was baffled by quantum gravity and in his theory of general relativity said there is no realistic experiment that could show a quantum version of gravity however physicists at the university of southampton working with scientists in europe have now successfully detected a weak gravitational pull on a tiny particle using a new technique they claim it could pave the way to finding the elusive quantum gravity theory the experiment published in the science advances journal used levitating magnets to detect gravity on microscopic particles  small enough to border on the quantum realm artist impression of the quantum experiment credit university of southampton lead author tim fuchs from the university of southampton said the results could help experts find the missing puzzle piece in our picture of reality he added for a century scientists have tried and failed to understand how gravity and quantum mechanics work together now we have successfully measured gravitational signals at the smallest mass ever recorded it means we are one step closer to finally realizing how it works in tandem from here we will start scaling the source down using this technique until we reach the quantum world on both sides by understanding quantum gravity we could solve some of the mysteries of our universe  like how it began what happens inside black holes or uniting all forces into one big theory the rules of the quantum realm are still not fully understood by science  but it is believed that particles and forces at a microscopic scale interact differently than regularsized objects academics from southampton conducted the experiment with scientists at leiden university in the netherlands and the institute for photonics and nanotechnologies in italy with funding from the eu horizon europe eic pathfinder grant qucom their study used a sophisticated setup involving superconducting devices known as traps with magnetic fields sensitive detectors and advanced vibration isolation it measured a weak pull just 30an on a tiny particle 043mg in size by levitating it in freezing temperatures a hundredth of a degree above absolute zero  about minus273 degrees celsius the results open the door for future experiments between even smaller objects and forces said professor of physics hendrik ulbricht also at the university of southampton he added we are pushing the boundaries of science that could lead to new discoveries about gravity and the quantum world our new technique that uses extremely cold temperatures and devices to isolate the vibration of the particle will likely prove the way forward for measuring quantum gravity unravelling these mysteries will help us unlock more secrets about the universes very fabric from the tiniest particles to the grandest cosmic structures reference measuring gravity with milligram levitated masses by tim m fuchs dennis g uitenbroek jaimy plugge noud van halteren jeanpaul van soest andrea vinante hendrik ulbricht and tjerk h oosterkamp 23 february 2024 science advances doi 101126sciadvadk2949,Physics
international scientists discovered that magnetostriction significantly influences muon localization in certain materials overturning previous assumptions in muon spectroscopy this breakthrough achieved through advanced simulations sheds light on the magnetic phase transitions in manganese oxide and has implications for studying similar materials muon spectroscopy serves as a crucial experimental method for exploring the magnetic characteristics of materials this technique involves embedding a spinpolarized muon within the crystal lattice and observing the impact of the surrounding environment on its behavior it operates on the principle that the muon will settle into a specific location predominantly influenced by electrostatic forces a position that can be pinpointed through the calculation of the materials electronic structure but a new study led by scientists in italy switzerland uk and germany has found that at least for some materials that is not the end of the story the muon site can change due to a wellknown but previously neglected effect magnetostriction pietro bonf from the university of parma lead author of the study just published in physical review letters explains that his group and their colleagues at the university of oxford uk have been using densityfunctional theory dft simulations for at least a decade to find muon sites we started with tricky cases such as europium oxide and manganese oxide and in both cases we could not find a reasonable way to reconcile dft predictions and the experiments he says we then tested simpler systems and we had many successful predictions but those two cases were really bothering us these compounds should be easy but instead turned out to be super complicated and we did not understand what was happening manganese oxide is a textbook case of an antiferromagnetic system and we could not explain muon spectroscopy results for it which was a bit embarrassing the problem he explains was the contradiction between the expectation to find the muon in a high symmetry position and its wellknown tendency to make bonds with oxygen atoms the antiferromagnetic order of the material reduces the symmetry and the position close to the oxygen atoms becomes incompatible with experiments bonf suspected that the explanation could be linked to the material undergoing a magnetic phase transition and started trying to reproduce the phenomenon in simulations of manganese oxide because it is a complicated system you must add some corrections to dft such as the hubbard u parameter he says but we were choosing its value empirically and when you do that you have a lot of uncertainty and the results can change dramatically depending on the value you choose still bonfs initial simulations suggested that the muon positions could be driven by magnetostriction a phenomenon that causes a material to change its shape and dimensions during magnetization to prove it beyond doubt he teamed up with the marvel laboratories at epfl and psi of nicola marzari and giovanni pizzi we used a stateoftheart method called dftuv which was very important to make simulations more accurate explains iurii timrov a scientist in the laboratory for materials simulations at psi and coauthor of the study this method can be used with onsite u and intersite v hubbard parameters that are computed from first principles instead of being chosen empirically thanks to the use of densityfunctional perturbation theory for dftuv that was developed within marvel and implemented in the quantum espresso package although we had already figured out that magnetostriction was at play having the correct information on the building blocks of the simulation was very important and that came from iuriis work adds bonf in the end the solution of the puzzle was relatively simple magnetostriction which is the interplay between magnetic and elastic degrees of freedom in the material causes a magnetic phase transition in mno at 118k at which the muon site switches above that temperature the muon becomes delocalized around a network of equivalent sites  which explains the unusual behavior observed in experiments at high temperatures the scientists expect that the same may be true also for many other rocksaltstructured magnetic oxides in the future timrov explains the group wants to keep studying the same material also including temperature effects using another advanced technique developed in marvel and called stochastic selfconsistent harmonic approximation in addition and in collaboration with giovanni pizzis group at the paul scherrer institute this approach will be made available to the community through the aiidalab interface so that all experimentalists can use it for their own studies reference magnetostrictiondriven muon localization in an antiferromagnetic oxide by pietro bonf ifeanyi john onuorah franz lang iurii timrov lorenzo monacelli chennan wang xiao sun oleg petracic giovanni pizzi nicola marzari stephen j blundell and roberto de renzi 24 january 2024 physical review letters doi 101103physrevlett132046701 the study was funded by the swiss national science foundation,Physics
scientists at the does brookhaven national laboratory have discovered that coating tantalum with magnesium significantly enhances its properties as a superconducting material for quantum computing this coating prevents oxidation increases purity and improves the superconducting transition temperature of tantalum offering promising advancements for the development of qubits and the future of quantum computing scientists at the us department of energys doe brookhaven national laboratory have discovered that adding a layer of magnesium improves the properties of tantalum a superconducting material that shows great promise for building qubits the basis of quantum computers as described in a paper just published in the journal advanced materials a thin layer of magnesium keeps tantalum from oxidizing improves its purity and raises the temperature at which it operates as a superconductor all three may increase tantalums ability to hold onto quantum information in qubits this work builds on earlier studies in which a team from brookhavens center for functional nanomaterials cfn brookhavens national synchrotron light source ii nslsii and princeton university sought to understand the tantalizing characteristics of tantalum and then worked with scientists in brookhavens condensed matter physics  materials science cmpms department and theorists at does pacific northwest national laboratory pnnl to reveal details about how the material oxidizes those studies showed why oxidation is an issue when oxygen reacts with tantalum it forms an amorphous insulating layer that saps tiny bits of energy from the current moving through the tantalum lattice that energy loss disrupts quantum coherencethe materials ability to hold onto quantum information in a coherent state explained cfn scientist mingzhao liu a lead author on the earlier studies and the new work these molecular diagrams compare the oxidation of native tantalum ta left in which the oxide penetrates the ta lattice with that of tantalum coated with an ultrathin layer of magnesium mg right mg acts as an oxygen barrier effectively suppressing ta oxidation and pulls impurities from ta both improve the superconducting properties of the underlaying ta thin filmshown in the graphs as a sharper transition to superconductivity at a higher temperature credit brookhaven national laboratory while the oxidation of tantalum is usually selflimitinga key reason for its relatively long coherence timethe team wanted to explore strategies to further restrain oxidation to see if they could improve the materials performance the reason tantalum oxidizes is that you have to handle it in air and the oxygen in the air will react with the surface liu explained so as chemists can we do something to stop that process one strategy is to find something to cover it up all this work is being carried out as part of the codesign center for quantum advantage c2qa a brookhavenled national quantum information science research center while ongoing studies explore different kinds of cover materials the new paper describes a promising first approach coating the tantalum with a thin layer of magnesium when you make a tantalum film it is always in a highvacuum chamber so there is not much oxygen to speak of said liu the problem always happens when you take it out so we thought without breaking the vacuum after we put the tantalum layer down maybe we can put another layer like magnesium on top to block the surface from interacting with the air studies using transmission electron microscopy to image structural and chemical properties of the material atomic layer by atomic layer showed that the strategy to coat tantalum with magnesium was remarkably successful the magnesium formed a thin layer of magnesium oxide on the tantalum surface that appears to keep oxygen from getting through chenyu zhou a research associate in the center for functional nanomaterials cfn at brookhaven national laboratory and first author on the study with mingzhao liu cfn yimei zhu cmpms and junsik mun cfn and cmpmsd at the dynacool physical property measurement system ppms in cfn the team used this tool to make tantalum thin films with and without a protective magnesium layer so they could determine whether the magnesium coating would minimize tantalum oxidation credit jessica rotkiewiczbrookhaven national laboratory electron microscopy techniques developed at brookhaven lab enabled direct visualization not only of the chemical distribution and atomic arrangement within the thin magnesium coating layer and the tantalum film but also of the changes of their oxidation states said yimei zhu a study coauthor from cmpms this information is extremely valuable in comprehending the materials electronic behavior he noted xray photoelectron spectroscopy studies at nslsii revealed the impact of the magnesium coating on limiting the formation of tantalum oxide the measurements indicated that an extremely thin layer of tantalum oxideless than one nanometer thickremains confined directly beneath the magnesiumtantalum interface without disrupting the rest of the tantalum lattice this is in stark contrast to uncoated tantalum where the tantalum oxide layer can be more than three nanometers thickand significantly more disruptive to the electronic properties of tantalum said study coauthor andrew walter a lead beamline scientist in the soft xray scattering  spectroscopy program at nslsii collaborators at pnnl then used computational modeling at the atomic scale to identify the most likely arrangements and interactions of the atoms based on their binding energies and other characteristics these simulations helped the team develop a mechanistic understanding of why magnesium works so well at the simplest level the calculations revealed that magnesium has a higher affinity for oxygen than tantalum does while oxygen has a high affinity to tantalum it is happier to stay with the magnesium than with the tantalum said peter sushko one of the pnnl theorists so the magnesium reacts with oxygen to form a protective magnesium oxide layer you dont even need that much magnesium to do the job just two nanometers of thickness of magnesium almost completely blocks the oxidation of tantalum the scientists also demonstrated that the protection lasts a long time even after one month the tantalum is still in pretty good shape magnesium is a really good oxygen barrier liu concluded the magnesium had an unexpected beneficial effect it sponged out inadvertent impurities in the tantalum and as a result raised the temperature at which it operates as a superconductor even though we are making these materials in a vacuum there is always some residual gasoxygen nitrogen water vapor hydrogen and tantalum is very good at sucking up these impurities liu explained no matter how careful you are you will always have these impurities in your tantalum but when the scientists added the magnesium coating they discovered that its strong affinity for the impurities pulled them out the resulting purer tantalum had a higher superconducting transition temperature that could be very important for applications because most superconductors must be kept very cold to operate in these ultracold conditions most of the conducting electrons pair up and move through the material with no resistance even a slight elevation in the transition temperature could reduce the number of remaining unpaired electrons liu said potentially making the material a better superconductor and increasing its quantum coherence time there will have to be followup studies to see if this material improves qubit performance liu said but this work provides valuable insights and new materials design principles that could help pave the way to the realization of largescale highperformance quantum computing systems reference ultrathin magnesiumbased coating as an efficient oxygen barrier for superconducting circuit materials by chenyu zhou junsik mun juntao yao aswin kumar anbalagan mohammad d hossain russell a mclellan ruoshui li kim kisslinger gengnan li xiao tong ashley r head conan weiland steven l hulbert andrew l walter qiang li yimei zhu peter v sushko and mingzhao liu 10 january 2024 advanced materials doi 101002adma202310280 this research was funded by the doe office of science the scientists used the spectroscopy soft and tender beamlines sst1 and sst2 at nslsii which are operated by the national institute of standards and technology nist materials synthesis  characterization proximal probe and electron microscopy facilities at cfn facilities of the electron microscopy and nanostructure group and advanced energy materials group in cmpms and computational resources of the national energy research scientific computing center nersc at does lawrence berkeley national laboratory cfn nslsii and nersc are doe office of science user facilities the study included additional coauthors from cfn cmpms nslsii pnnl princeton university stony brook university and nist,Physics
as a site reliability engineer one of the key metrics that i use to track the effectiveness of incident management is mean time to recover mttr based on wikipedia mttr is defined as the average time that a service or system will take to recover from any failure trying to achieve a low mttr is key to achieving service level objectives and in turn service level agreements of any critical production service service level indicators or slis are the key indicators that measure the health of your service a few examples of slis are error rate latency throughput etc the alert strategy should include improving the signaltonoise ratio of the alerts the goal with alerting is that every alert that your team gets should be actionable sending too many alerts will cause alert fatigue and will have the risk of the oncall person ignoring alerts that indicate real issues with the service every alert should have a clearly defined troubleshooting guide on how to triage and mitigate the issue the alert identifies a good methodology to use while writing these troubleshooting guides is the use methodology suggested by brendan gregg in his book systems performance use stands for usage saturation and errors practicing troubleshooting guides periodically will help mitigate incidents when they occur it will also help identify gaps with the tsgs since services evolve over time a few examples of a good time to practice troubleshooting guides is when a new team member joins the team so that they can give a fresh perspective of the tsg this will reduce assumptions about the knowledge of the system the observability strategy should include creating easytouse dashboards the dashboards should have panels to include the key metrics of the services and the health of dependent services such as upstream and downstream services a few examples of important metrics that should be included in the dashboards are the golden signals suggested by the google sre book such as latency throughput error rate and saturation metrics automating certain actions based on the metrics and events is key to reducing mttr an example of this is taking certain servers out of rotation if packet loss is observed from these servers this will help reduce the impact on user experience and reduce mttr in the case of multidata center architectures it is crucial to have failover plans defined to make sure to recover from an outage of a specific data center quickly practicing these failover scenarios periodically will help to quickly execute them during an outage this will also help in identifying any gaps in the failover plans and give the chance to update and fix the failover plans once the failover plans are defined implemented and practiced the next step is to automate these failover scenarios based on the health checks of the service on a given data center this will help to mitigate the issues faster and thus reduce the mttr changes to production systems are a major cause of outages it is important to have a wellthoughtout change management process in place a few key elements of the change management process should include clearly defined checklists change review and approval procedures automated deployment pipelines with builtin monitoring and the ability to quickly roll back the changes if any issues are observed there can be multiple changes continuously done in distributed systems where services are designed as microservices having a central system where one can easily identify which changes have been done during a given period of time will help to identify if a specific change has caused an outage and is thus easy to roll back in this article i have discussed 10 things that can help reduce the mean time to recovery of any critical production service this is not an exhaustive list but a list of best practices based on my years of experience working as a site reliability engineer on services such as tiktok microsoft teams xbox and microsoft dynamics opinions expressed by dzone contributors are their own,Computing
scientists have found that immersing kids in computer games can train their brains to localise sounds better scientists have recruited an unusual ally in their efforts to help children overcome profound deafness they are using computer games to boost the childrens ability to localise sounds and understand speech the project is known as bears  for both ears  and it is aimed at youngsters who have been given twin cochlea implants because they were born with little or no hearing these are children who are profoundly deaf said audio engineer lorenzo picinali a scientist on the project from imperial college london they require major interventions to restore their hearing and we have found that computer games can make these much more effective in one game a player  wearing a virtual reality headset  operates a food stall and wins points for each order that is completed the tempo hots up and the player receives increasingly elaborate requests from cartoon characters these are fired at them at faster and faster from different directions at the same time background noises become louder and more confusing its very challenging but the game improves a childs ability to localise sound and that in turn helps them understand speech added picinali our research has shown that the better you are at localising a sound  in pinpointing the location of a noise  then you also get better understanding what someone is saying to you their speech becomes clearer in noisy situations by using computer games we can help the person to boost their ability to localise sound and in the process to understand speech all sorts of factors affect how a person picks up sounds added picinali including the size of their head or the shape of their ears other innovations developed at imperial include a computer game in which children aim at targets that become fainter and fainter until they can only be pinpointed by acoustic cues others require players using differences in pitch to aim at soundemitting targets the crucial point is that children with implants were involved in designing the games said picinali they have played a key role in the development of the project from the start unlike hearing aids which merely amplify sounds and are therefore of little to use to profoundly deaf children cochlea implants  which are fitted to the skull behind the ears  turn vibrations in the air into electrical signals that can be transmitted to the brain where they are experienced as sound however these signals are often confusing and disorienting and can result in users receive highly distorted sounds localising sounds and listening to conversations in noisy places is still very difficult to comprehend using a cochlea implant and some wearers find they simply cannot adjust to the sounds they produce sign up to observed analysis and opinion on the weeks news and culture brought to you by the best observer writers after newsletter promotion an implant is a lifeline for profoundly deaf children but they are not easy to get used to said picinali we needed to find ways to make them easier to understand the signals being sent to their brains  and training with computer games should make a vital difference what we are doing is helping them remap their hearing systems there are about 6500 children in the uk who are profoundly deaf and for whom a cochlea implant is the only hope for restoring their hearing with the help of the comprehensive clinical trials unit at university college london the project  which is led by debi vickers at cambridge university and dan jiang at guys and st thomas hospital in london will recruit more than 300 youngsters with hearing difficulties and will be completed in about 18 months the end result it is hoped will not just aid children with cochlea implants but could make major improvement to the hearing of all deaf children about 50000 children in the uk all sorts of different causes can produce severe deafness in children from genetics to accidents and infections added katarina poole another member of the imperial team this could make a major difference for the lives of thousands of children,Computing
the family of michael schumacher have won their legal action against the publisher of a magazine that printed an artificial intelligencegenerated interview with the multiple formula one champion the german celebrity magazine die aktuelle promoted on its cover in april 2023 the words michael schumacher the first interview it also wrote it sounds deceptively real with the supposed quotes attributed to schumacher generated by ai sabine kehm the family spokesperson told the associated press by email on thursday that legal action was successful without making any further comment the compensation amount was reportedly 200000 the german publisher funke magazines apologised to schumachers family last year for the article and fired anne hoffmann the chief editor of die aktuelle this tasteless and misleading article should never have appeared said funkes managing director bianca pohlmann at the time it in no way meets the standards of journalism that we and our readers expect from a publisher like funke it was while skiing in the french alps at meribel that schumacher fell in december 2013 and suffered a near fatal brain injury his head hit a rock that split open his helmet since being transferred from hospital in september 2014 the seventime f1 champion has been cared for privately at a family home in switzerland the 55yearold schumacher had retired from f1 in 2012 after winning 91 races and five straight titles with ferrari from 200004 the german drivers other two titles were with benetton in 1994 and 1995,Computing
over the last few years artificial intelligence ai especially generative ai has permeated all sectors growing smarter and faster  and spreading a ubiquitous presence generative ai can lead to competitive advantage and the large language models llms that underpin ai and the everexpanding use cases have evolved faster than any tech in history but ai also has the potential for misuse raising fundamental questions regarding its human and ethical impact these questions demand immediate answers as ais influence continues to spread this article offers food for thought and some advice for the way forward ai is not a problem for tomorrow  its already here the horse has well and truly bolted openais chatgpt set a record for the fastestgrowing user base gaining 100 million monthly active users within the first two months according to open ai millions of developers and more than 92 of fortune 500 are building on our products today many startups and enterprises use tech for good such as helping people who stutter speak more clearly detecting landmines and designing personalized medicine however ai can also be used in ways that cause harm such as misidentifying suspects defaming journalists breaching artistic copyright and developing deepfakes that can steal millions furthermore the datasets within the llms that power ai can be gender or racially biased or contain illegal images therefore ai regulations must examine existing problems and anticipate future problems which will evolve as llms provide new use cases across various industries many of which we never thought possible the latter is no easy task todays ai has created entirely new business opportunities and economic advantages that will make enterprises resistant to change but change is possible as gdpr regulations in europe demonstrate especially since compliance failure results in fines proportional to a business earnings depending on factors such as intent damage mitigation and cooperation with authorities regarding governance europe has passed the artificial intelligence act which aims to protect fundamental rights democracy the rule of law and environmental sustainability from highrisk ai according to its potential risks and level of impact and in north america the defense production act will require tech companies to let the government know when they train an ai model using a significant amount of computing power the presidents executive order eo charges multiple agencies  including nist  with producing guidelines and taking other actions to advance the safe secure and trustworthy development and use of ai the uk hosted the first global ai safety summit last autumn and is building an aigovernance framework that embraces the transformative benefits of ai while being able to address emerging risks india has yet to implement specific ai regulations we dont know what these regulations will mean in practice as they have yet to be tested in law however there are multiple active litigations against generative ai companies theres currently civil action against microsoft github and openai claiming that by training their ai systems on public github repositories  they violated the legal rights of a vast number of creators who posted code under certain opensource licenses on github writer sarah silverman has a similar claim against meta and openai for alleged copyright infringement this is very different from having legislation requiring responsible ai from the design phase with financial and legal penalties for companies that create ai that breaches regulations until the regulations are tested with enough heft to disincentivize the creation and use of unethical ai such as deepfakes and racial bias i predict a lot of david vs goliath cases where the onus is on the individuals harmed going up against tech behemoths and spending years in court generative ai can be used to work better and faster than competitors but it can breach regulations like gdpr share company secrets and break customer confidentiality most people fail to understand that chatgpt retains user input data to train itself further thus confidential data and competitive secrets are no longer private and are up for grabs by openais algorithm multiple studies show employees uploading sensitive data including personal identifiable information pii to openais chatgpt platform the amount of sensitive data uploaded to chatgpt by employees increased by 60 between just march and april 2023 salesforce surveyed over 14000 global workers across 14 countries and found that 28 of workers use generative ai at work and over half without formal employer approval in 2023 engineers at samsungs semiconductor arm used chatgpt to input confidential data such as source code for a new program and internal meeting notes in response samsung is developing its own ai models for internal use and restricting employee use to prompts with a 1024byte limit theres also the issue of how ai is used as part of an enterprises service offerings ostensibly to increase efficiency and reduce manual tasks for example decisionmaking ai in the enterprise can choose one potential employee over another in recruitment or predict a tenants ability to pay rent in housing software companies cant simply blame bad outcomes on ai there must be a human overseer to address any potential or identified issues generated by the use of ai they also must create effective channels for users to report concerns and provide feedback about decisions made by ai such as chatbots clear policies and training are also necessary to hold employees accountable for responsible ai use and establish consequences for unethical behavior governments are constantly trying to balance the regulation of ai against tech advancement and the more you delve into it the more the need for a human overseer emerges theres plenty of talk about ai making tasks easier and reducing pain points at work but what happens to telemarketers data clerks copywriters etc who find their roles obsolete because ai can do it faster and better i dont believe programs like universal basic income will provide adequate financial security for those whose jobs are replaced by ai nor do all displaced people want to transition to physical roles like senior care or childcare we need a focus on upskilling and reskilling workers to ensure they have the necessary skills to continue meaningful employment of their choosing there is a pervasive challenge in the dominance of large companies responsible for most tools especially where smaller companies and governments build products on top of their models and opensource ai what if opensource models become proprietary or raise their prices so startups can no longer afford to create commercial products preventing largescale innovation this is hugely problematic as it means that smaller companies cannot compete equitably in the economic market theres also sovereignty most llms originate from the us meaning the data generated is more likely to be embedded with north american perspectives this geographical skew creates a real risk that north american perspectives biases and cultural nuances will heavily influence users understanding of the world this increases the chance of algorithmic bias cultural insensitivity and ultimately inaccuracies for users seeking information or completing tasks outside the dominant data landscape international companies in particular have the opportunity to ensure that llms have diverse data representation with global perspectives opensource collaboration is an effective way to foster this and already has the necessary frameworks creating custom llms is no easy task on an infrastructural level  its expensive especially when you factor in the cost of talent hardware infrastructure and compute power gpus power ai workloads and training but theyve been in short supply since the covid19 pandemic with gpus earmarked for 2024 already sold out some countries are buying up gpus the uk is planning to spend 1263 million to purchase ai chips this will leave fewer resources for less prosperous nations intentionally fostering innovation between developed and developing nations is crucial to facilitate knowledgesharing more equitable resource allocation and joint development efforts it also requires targeting funding and support for local infrastructure company accountability for unethical ai  whether by design deployment or unintentional misuse  is complex especially as we have yet to see the net result of ai regulations in practice accountability involves detecting and measuring the impact of unethical ai and determining the appropriate penalties existing regulations in industries such as financial services and healthcare are likely to help establish parameters but each industry needs to predict and respond to its unique challenges for example the world health organization suggests liability rules so users harmed by an llm in healthcare are adequately compensated or have other forms of redress to reduce the burden of proof thus ensuring fair compensation were only just getting started and companies that commit to ethical ai as their earliest use cases will be able to adapt easier and faster to whatever regulations come over the following months and years ethical ai in practice involves intentionality ongoing commitment to design auditing and an environment willing to look at the risks associated with ai companies that embed this commitment throughout their organization will succeed the last few years have seen companies like x and google reduce their responsible ai teams a dedicated team or role can assist with proactive risk management building a transparent culture and employee training however an ai ethicist or a responsible ai team only works if they have a place in the company hierarchy where they can drive and influence bottomline business decisions with business managers developers and the csuite otherwise the role is simply a public relations spin theres also the temptation that hiring a dedicated person or team makes ethics someone elses problem assigning ethics to a single individual or team could create a false sense of security and neglect broader responsibility across the organization especially if it comes at the expense of embedding responsible ai from the earliest design phase and seeing it as a valuable asset to a companys brand creating an ai policy is useful but needs to be embedded in your companys practices rather than simply be something that gets shared to keep investors happy ultimately companies that want to practice responsible ethical ai need to have this commitment embedded into their dna much like a securityfirst approach this means active working ai policies that are amenable align with innovation and spread responsibility throughout the workplace for example companies like microsoft highlight key factors in what ethical ai should look like encompassing companies can also weatherproof themselves by committing to using tools and services focused on ethical ai some examples include ai is complex and ultimately this article poses as many questions as answers when tech capabilities use cases and repercussions are everevolving continual discussions and an actionable commitment to ethics is vital a company that commits to ethical ai in its early iterations weatherproofs itself from the incoming regulations and possible penalties for ai misuse but most importantly committing to ethical ai protects a companys identity and competitive advantage resources this is an excerpt from dzones 2024 trend report enterprise ai the emerging landscape of knowledge engineeringread the free report opinions expressed by dzone contributors are their own,Computing
as the landscape of artificial intelligence continues to evolve the development and refinement of large language models llms such as gpt3 gpt4 has marked significant advancements in how these models are applied across various industries this whitepaper delves into the evolution of llms explores the strategic application of finetuning discusses the use cases for different finetuning approaches and examines the capabilities of new technologies like lorax which is reshaping the future of finetuning at scale originally simple text prediction tools llms have transformed into robust contextaware systems capable of generating humanlike text this evolution was largely propelled by innovations such as the transformer architecture which revolutionized data processing within neural networks recent developments have seen these models expand in size and capability integrating vast amounts of data hence called pretrained models to improve their predictive accuracies and contextual sensitivities customization of llms is finetuning there are two approaches to customization of llms while pretrained llms offer impressive performance out of the box finetuning allows practitioners to adapt these models to specific tasks or domains thereby improving their effectiveness and relevance finetuning becomes necessary when the task at hand requires specialized knowledge or when the available pretrained model needs to be customized for a particular use case by finetuning practitioners can leverage the general language understanding capabilities of pretrained llms while tailoring them to specific requirements leading to better performance and efficiency finetuning is particularly valuable when finetuning should be considered a complementary strategy alongside prompt engineering and retrieval techniques retrieval augmented generationrag often requiring both to achieve optimal performance starting with prompt engineering is advisable to gauge how far the base model can go before investing in finetuning a groundbreaking development in the field of llms is the lorax framework which enables the deployment of hundreds of finetuned models on a single gpu this system significantly reduces the costs and logistical complexities associated with running multiple llms in parallel lorax employs a novel approach called parameterefficient finetuning which adds a minimal number of trainable parameters to a large pretrained model this technique often utilizing methods such as lowrank adaptation lora maintains the integrity of the original models weights while making precise adjustments to tailor the model for specific tasks the difference between full fine tuning and parameter efficient fine tuning is illustrated below  as per the above illustration full fine tuning is expensive and not always required unless there is research and development for building a new model grounds up needed to optimize the cost at the same time you own the model and the ip parameter efficient fine tuning is the recommended finetuning approach with respect to the model deployment for finetuning there needs to be a conscious decision on how many models need to be finetuned for your business use case will drive the necessity of leveraging lorax two deployment approaches for model finetuning at scale are illustrated the first one is without lorax and the second approach is with lorax which allows finetuning models at scale  loraxs capabilities extend beyond simple cost reduction it introduces several innovative features that enhance its performance the future of finetuning at scale promises more automated intelligent systems that reduce the reliance on large computational resources innovations like lorax are paving the way toward more sustainable ai practices by enabling more precise model customization without the extensive overhead typically associated with largescale llm deployments as ai technology continues to advance we can expect to see an increase in solutions that not only enhance performance but also promote greater personalization efficiency and lower environmental impact in conclusion the development of llms and the advent of technologies like lorax lora exchange highlight a significant shift towards more specialized efficient and scalable ai solutions these advancements are set to revolutionize how businesses deploy ai making it a more integral and tailored part of their operational toolkit thereby driving further adoption across various sectors opinions expressed by dzone contributors are their own,Computing
a joint investment by the australian federal government and the government of queensland makes psiquantum one of the largest dedicated quantum computing firms in the world by james woodford 30 april 2024 a silicon photonic chip from psiquantumpsiquantum a silicon photonic chip from psiquantum psiquantum the australian government has announced it will invest nearly a1 billion into the development of quantum computers staking a claim in a race currently dominated by the us and china psiquantum which is headquartered in the us but was cofounded by a team including two australian researchers will get a470 million from both australias federal government and the state government of queensland totalling a940m 613m in return the company will build and operate successive generations of its quantum computers in brisbane australia read more microsoft and quantinuums quantum computer may be most reliable yet read more microsoft and quantinuums quantum computer may be most reliable yet advertisement stephen bartlett at the university of sydney says the announcement amounts to australia staking a claim to sovereign capability in quantum computing and building up a quantum technology ecosystem what gets me really excited about this is that the scale of investment means we are serious says bartlett while big technology companies like ibm google and microsoft have made multibillion dollar investments in quantum computing australias funding makes psiquantum one of the biggest dedicated quantum computing companies in the world quantum computers offer the potential to complete some tasks much faster than any ordinary computer to date such capabilities have only been demonstrated on problems with no practical applications but as research teams in the us china and elsewhere race to build larger and less errorprone machines the hope is they will start proving useful the latest science news delivered to your inbox every day while many teams are building quantum computers based on superconductors psiquantums approach involves particles of light called photons a method which had been seen as difficult to scale up but ahead of the australian announcement psiquantum published a paper detailing how it has been able to use a standard semiconductor fabrication setup of the type used to make ordinary computer chips to build the photonic chips it needs for quantum machines read more quantum computer sets record on path towards errorfree calculations read more quantum computer sets record on path towards errorfree calculations australia has exported a generation of quantum researchers including psiquantum cofounders jeremy obrien and terry rudolph the government investment may entice such scientists to begin returning and building careers in australia says bartlett australia is saying we are going to sit at the big table when it comes to quantum computing topics advertisement receive a weekly dose of discovery in your inbox well also keep you up to date with new scientist events and special offers,Computing
three new protocols for generating verifiable quantum entanglement between two nodes in a network have been developed independently by teams in china europe and the us the research which allows distant quantum memories to exchange quantum information may constitute a step towards a quantum version of the internet in which photons travelling down standard optical fibres are used to entangle spatially separated quantum computers the delicate nature of quantum information means it does not travel well a quantum internet therefore needs devices known as quantum repeaters to swap entanglement between quantum bits or qubits at intermediate points several researchers have taken steps towards this goal by distributing entanglement between multiple nodes in 2020 for example xiaohui bao and colleagues in jianwei pans group at the university of science and technology of china ustc entangled two ensembles of rubidium87 atoms in vapour cells using photons that had passed down 50 km of commercial optical fibre creating a functional quantum repeater is more complex however a lot of these works that talk about distribution over 50 100 or 200 kilometres are just talking about sending out entangled photons not about interfacing with a fully quantum network at the other side explains can knaut a phd student at harvard university and a member of the us team in their latest work which is published in nature alongside that of the harvard team bao and colleagues present a more practicable system at each node they use a scheme called the duanlukinciraczoller dlcz protocol that involves injecting a laser pulse into each of their atomic ensembles this write pulse is composed of many photons bao explains and there is a small chance that it will excite one atom to another state the excited atom then spontaneously emits a photon becoming entangled with a collective state of the atomic ensemble in the process the emitted photons are then sent to a central node where a measurement is performed that entangles the two ensembles the catch is that the dlcz protocol requires the write pulses at each node to be phasecoherent which is hard to achieve in spatially separated nodes in their 2020 work the ustc researchers did it by sending pulses from the same laser through a beamsplitter but this would be impractical for realworld networks in the new work they stabilized the phases of independent lasers in three locations approximately 125 km apart around a central node and demonstrated that they could entangle ensembles at all of them by using atomic ensembles it is rather easy to convert from atomic qubits to single photons bao notes the other two teams worked with solidstate quantum memories made from vacancy centres in diamond the first headed by ronald hanson at qutech in the netherlands stores the state of the qubit in the electronic state of a nitrogenvacancy centre as described in a recent arxiv preprint the second led by harvards mikhail lukin uses siliconvacancy centres these have a much more stable and coherent optical transition than their nitrogen counterparts but their electronic spins are less stable losing coherence within about 200 s this short coherence time is problematic because entanglement cannot be used to transfer information unless the entangled states remain coherent long enough for the entanglement to be heralded  that is for information to travel down a classical channel and confirm the success of the entangling operation if you cannot store your entanglement longer than a couple of hundred microseconds its essentially useless because at the point when you want to start using it its already gone knaut says the harvard team circumvented this problem using something called a photonnucleus entangling phone gate which members of lukins group invented in 2022 this phone gate utilizes the electron spin but only temporarily as an interface it immediately transfers the information to the nuclear spin and the nuclear spin is very longlived lukin says lukin and colleagues also avoided the need to measure the photons at a central node instead they used a serial entanglement protocol when the photon comes to the first node it gets entangled  you basically do a gate operation between the photon and one of the qubits in the memory explains lukin then the photon comes to another node you do another logic gate between the photon and the memory and then eventually you measure a photon its like a distributed quantum computer the flexibility of this scheme enabled them to avoid keeping track of the phase of the photon emitted directly from the vacancy instead they encoded the state of the qubit into two time bins  peaks in the electomagnetic field spaced 142 ns apart its a single photon conceptually but it is a superposition of two time bins knaut says chris monroe of duke university us who was not involved in any of the works finds one aspect of them interesting quantum systems are very discriminating they work with very specific colours of light and they dont typically tend to be telecom wavelengths he says each of these groups has converted the native photon to a telecom photon and that has allowed them to go over a long distance quantum repeater transmits entanglement over 50 kilometres apart from this however he is sceptical the quantum internet are two buzzwords that dont mean a hell of a lot he says to build a big computer youre going to need a quantum network but it can be on one chipwere going to use photons to scale up period in a sense this recent work is sort of irrelevant to that pursuit note the verification email to complete your account registration should arrive immediately however in some cases it takes longer dont forget to check your spam folder if you havent received the email in 24 hours please contact ,Physics
